import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn as seabornInstance
%matplotlib inline
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neighbors import NearestNeighbors


people = pd.read_csv('people_wiki.csv')

people.head(5)

len(people)

obama = people[people['name'] == 'Barack Obama']

obama

obama['text']

obama['word_count'] = obama['text'].apply(lambda x: Counter(x.lower().split()))

df = obama['word_count']

df.head(5)

# df1 = pd.DataFrame(df, columns=['Name', 'Values']) 
df1 = pd.DataFrame(list(obama['word_count'].items()),columns = ['column1','column2'])

del df1['column1']

df1

df2 = pd.DataFrame(list(df1.items()),columns = ['name','count'])

df2

people['word_count'] = people['text'].apply(lambda x: Counter(x.lower().split()))

people.head()

docs=people['word_count'].tolist()

cv=CountVectorizer(max_df=0.85)
word_count_vector=cv.fit_transform(docs)

v = TfidfVectorizer()
x = v.fit_transform(docs)

people['tfidf'] = x['docs']

clinton = people[people['name'] == 'Bill Clinton']

beckham = people[people['name'] == 'David Beckham']

knn = NearestNeighbors()

knn.fit(people, features=['tfidf'], label='name')

knn.query(obama)

swift = people[people['name'] == 'Tylor Swift']

knn.query(swift)
