import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn as seabornInstance
%matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics

sales = pd.read_csv('kc-house-data.csv')

#sales['date'] = pd.to_numeric(sales['date'],errors='coerce')
del sales['date']

sales.head(5)

## Exploring the data for housing sales

# setting the plot size for all plots
sns.set(rc={'figure.figsize':(16.7,13.27)})
# plotting the violinplot
sales.plot(x='sqft_living', y='price', style='o')
#sns.violinplot(x="sqft_living",y="price", data=sales)
plt.show()

## create a simple regression model

X = sales.iloc[:, :-1].values
y = sales.iloc[:, 1].values
# X = sales['sqft_living'].values.reshape(-1,1)
# y = sales['price'].values.reshape(-1,1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

regressor = LinearRegression()
regressor.fit(X_train, y_train)

## Evaluate the simple model

# print(regressor.intercept_)

# print(regressor.coef_)

y_pred = regressor.predict(X_test)

#RMSE
print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

# plt.plot(X_test['sqft_living'],y_test['price'],'.', X_test['sqft_living'], regressor.predict(X_test), '-')

print(regressor.intercept_)

print(regressor.coef_)

df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})
df.head(5)

df = df.head(25)
df.plot(kind='bar',figsize=(16,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()

plt.scatter(X_test, y_test,  color='gray')
plt.plot(X_test[:,0], y_pred, color='red', linewidth=2)
plt.show()

print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

X = sales[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'condition', 'grade', 'yr_built', 'zipcode', 'yr_renovated']].values
y = sales['price'].values

plt.figure(figsize=(15,10))
plt.tight_layout()
seabornInstance.distplot(sales['price'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

regressor = LinearRegression()  
regressor.fit(X_train, y_train)

# coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  
# coeff_df

y_pred = regressor.predict(X_test)

df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df1.head(5)

df1.plot(kind='bar',figsize=(10,8))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

print(regressor.intercept_)

print(regressor.coef_)

print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

# house1 = sales[sales.id == '7129300520'].values
# house = house1[1]
sales.head(5)
# print (sales.iloc[1])

house1 = sales[sales.id == 2487200875]
house1

print(house1['price'])

print(regressor.predict(house1))
